# Vision Transformer Large Configuration
# ========================================
# Configuration for training with Vision Transformer (ViT) Large model
# This model requires larger images and batch sizes for optimal performance

data:
  train_csv: data/aptos/train.csv
  train_img_dir: data/aptos/train_images
  test_csv: data/aptos/test.csv
  test_img_dir: data/aptos/test_images

model:
  # Vision Transformer Large with 16x16 patches
  model_name: vit_large_patch16_384
  num_classes: 5
  pretrained: true

training:
  # Smaller batch size due to larger model and image size
  batch_size: 8
  num_epochs: 30
  # Lower learning rate for fine-tuning large models
  learning_rate: 5.0e-05
  weight_decay: 0.0001

image:
  # Larger image size for ViT models
  img_size: 384

system:
  num_workers: 4
  seed: 42
  device: cuda

paths:
  checkpoint_dir: results/checkpoints/vit_large
  log_dir: results/logs/vit_large
